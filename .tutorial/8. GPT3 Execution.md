# Running GPT3
Hopefully you were able to implement inference and an interface on your own but regardless let's do it together!

## Generate Text
```python
def generate_text_gpt(input_string, max_length):
  response = openai.Completion.create(model="text-davinci-003",
                                      prompt=input_string,
                                      temperature=0,
                                      max_tokens=max_length,
                                      top_p=1,
                                      frequency_penalty=0,
                                      presence_penalty=0)
  answer = response.choices[0]['text']
  return (answer)
```
You can see the similarities between our function and the documentation with only a few minor changes. Namely, we wanted to be able to see all the parameters we could change to not forget.

Note: In this case, length is not the number of characters but tokens we are asking to be generated. Tokens are ~4 characters. 

## Gradio interface
The only thing we'll have to change here is swapping out the function our Gradio interface references. 

We should also comment out the lines downloading the T5 model so we do not load it for no reason. 

## Results!
Try using our new interface for the same NLP applications, how does it perform?
**We encourage you to try a bunch of inputs to see just how amazing these results can be.**
